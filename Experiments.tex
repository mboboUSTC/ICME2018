\section{EXPERIMENTS}
\label{sec:experiments}
In this section, we will evaluate our framework with different parameters and compare our method with several state-of-the-art methods on segmenting the synaptic cleft region in electron micrographs.

\noindent\textbf{Dataset.}
Synaptic images are obtained by cryo-electron tomography (CET), from which we can directly observe a native environment of synaptic structures in a high resolution (about $1500\times 1500$). 
%
\comments{
And localizing the accurate contour of a target region in such a cluttered environment is significantly challenging, due to the noises and low signal-to-noise ratio.
In this paper, our goal is to extract the synaptic cleft region, which is adjacent to a synapse and receives neurotransmitter molecules from another synapse.
}
Only the cleft between two synapses, whose width is about $20\sim30$ nm ($40\sim70$ pixels in our electron micrographs), might be the desired synaptic cleft.
%
We build a dataset of synaptic electron micrographs, including $400$ synaptic images for training and $159$ images for testing.
%
All the image are observed in the raw resolution and labeled by biomedical experts.

\noindent\textbf{Implementation details.}
The training strategy of our DeepLab module follows the original paper~\cite{Chen2016a}.
For such a large resolution, we crop a $321\times 321$ region from the original image as the input to DeepLab.
In order to avoid over fitting, the training dataset is augmented by flipping and rotation, which leads to finally $19200$ images.
%
During the curve evolving, $\alpha$, $\beta$, $\kappa$ and $\gamma$ are respectively set as $0.2$, $0.2$, $0.3$ and $1$, which can give a best performance in our dataset.
For synchronous growing, $\rho$ is set as $0.25$ and $\tau_1$, $\tau_2$ are $-\frac{\sqrt{2}}{2}$, $\frac{\sqrt{2}}{2}$ to constrain the growing direction deviating $[-\frac{\pi}{4},\frac{\pi}{4}]$ from the previous growing direction.
When $d^{t}$ is beyond the range of $[40,80]$, the growth is terminated.




We use two metrics~\cite{Cheng2017} to evaluate our method on the segmentation task:
a) pixel accuracy, which evaluates the percentage of positive true pixels over all pixels;
b) pixel intersection-over-union (IOU) averaged across different classes.
\xj{of different classes or just the cleft region?}
%
We compare our proposed method with several state-of-the-art segmentation methods, including FCN~\cite{Long2015}, U-net~\cite{Ronneberger2015}, DeepLab~\cite{Chen2016a} with two backbone architectures (VGG16 and ResNet101) and PSPNet~\cite{Zhao2016} on the synaptic cleft segmentation task. 


%%% move the discussion of Eq 4 to the algorithm part
\comments{
~ \noindent\textbf{Superiority of Eq.~\ref{Eq:update}.}
In this part, we visualize the deficiencies of traditional updating Eq.~\ref{Eq:GVF} in GVF and represent the superiority of our strategy of Eq.~\ref{Eq:update}.
Firstly, in some flat regions with small gradients $\mathbf{f}$, the external tension is too weak to drive $\mathbf{v}(s)$ to move against to internal tension.
Therefore, it requires the initial curve to be away from the flat regions (Fig.~\ref{fig:gvf} (a)).
Secondly, the external tension in some noisy regions will be gyrate, which easily trap some $\mathbf{v}(s)$ (Fig.~\ref{fig:gvf} (b)).
Although sometimes the internal tension may pull the trapped point out, the gyrate $\mathbf{f}$ will trap it again.
And using Eq.~\ref{Eq:update} , once $\mathbf{v}(s)$ is pulled away from the noisy region, our external tension with fixed normal direction will soon push it away.
Thirdly, as the gradients $\mathbf{f}$ near to contours are usually large (Fig.~\ref{fig:gvf} (c)), $\mathbf{v}(s)$ easily cross the optimal positions by over-huge tension, while our external tension are controlled by $E_{ext}$, which will soon vanish in contour region and make the updating more robust.
}



Table~\ref{tab:report1} reports the pixel accuracy and mean IOU of different methods, while Fig.~ represents some visual instances of these methods.
Our model gives the best performance among existing methods and our localized contours are much more precise and complete than any single FCN-based method.
\change{Fig. show the segmentation results generated by different 
methods.}
%
Especially, Unet performs better than FCN and DeepLab-VGG16, due to richer features extracted by the U-shaped architecture.
%
The effects of pyramid pooling module used in the PSPNet are not obvious compared to DeepLab-ResNet101 in our task.
And the results of DeepLab-ResNet101 and PSPNet are better than other FCNs, which demonstrates the effectiveness of deeper ResNet.
From \change{Fig. }, FCNs can localize the correct positions of synaptic cleft in most cases, but their contours are not precise enough for further analysis.

\begin{table}[t]
\begin{center}
\caption{\change{Table caption}} \label{tab:report1}
\begin{tabular}{|c|c|c|}
  \hline
  % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
   & Pixel Accu. & mean IOU
  \\
  \hline
  FCN~\cite{Long2015} & 0.9923 & 0.5258 \\
  Unet~\cite{Ronneberger2015} &  0.9939 & 0.6359 \\
  DeepLab-VGG16~\cite{Chen2016a} & 0.9838 & 0.5867 \\
  DeepLab-ResNet101~\cite{Chen2016a} & 0.9951 & 0.7164 \\
  PSPNet~\cite{Zhao2016} & \change{Cell 5} & \change{Cell 6} \\
  Ours & $\mathbf{0.9974}$ & $\mathbf{0.7848}$ \\
  \hline
\end{tabular}
\end{center}
\end{table}


In order to further demonstrate the robustness of our approach to different initial segmentation, we explore the effects of various pre-segmentation module on our contour growing results.
%
It should be noted that DeepLab in Table~\ref{tab:report2} indicates the ResNet101 version of DeepLab, which is our default pre-segmentation network.
From the results in Table~\ref{tab:report2}, it demonstrates that our contour growing algorithm can obviously improve the results of different pre-segmentation model.
And observed from Fig.~\ref{}, as long as the correct location of synaptic cleft region is provided (Unet, DeepLab and PSPNet), our model can well localize the whole contours of target region.

\begin{table}[t]
\begin{center}
\caption{\change{Table caption}} \label{tab:report2}
\begin{tabular}{|c|c|c|}
  \hline
  % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
   & Pixel Accu. & mean IOU
  \\
  \hline
  Contour Growing$+$FCN & 0.9956 & 0.6339 \\
  Contour Growing$+$Unet & 0.9962 & 0.7720 \\
  Contour Growing$+$DeepLab & \textbf{0.9974} & \textbf{0.7848} \\
  Contour Growing$+$PSPNet & Cell 5 & Cell 6 \\
  \hline
\end{tabular}
\end{center}
\end{table}
